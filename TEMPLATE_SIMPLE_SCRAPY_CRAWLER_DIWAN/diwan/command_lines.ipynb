{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/gcp_SCRAPING_ALDIWAN/diwan'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HLPER FUNCTION: Get Time Now:\n",
    "from datetime import datetime\n",
    "def time_now():\n",
    "    '''Get Current Time'''\n",
    "    \n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S.%f\")\n",
    "    print(\"Current Time =\", current_time)\n",
    "    return now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **GOOGLE STORAGE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "PUTI GOOGLE STORAGE ADDRESS BELOW ok\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ok'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input('PUTI GOOGLE STORAGE ADDRESS BELOW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_path = \"gs://sheikh-fitzgerald/ALDIWAN/DIWAN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='{asctime} {levelname:<8} {message}',\n",
    "    style='{',\n",
    "    filename='scraping_diwan_log.log',\n",
    "    filemode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "spiders_folder = './diwan/spiders/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "spiders_list = [i for i in os.listdir(spiders_folder) if ((i.startswith('poem')) and (i.endswith('py')))]\n",
    "spiders_list = [i[:-3] for i in spiders_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "spiders_list = sorted(spiders_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['poem_01',\n",
       " 'poem_02',\n",
       " 'poem_03',\n",
       " 'poem_04',\n",
       " 'poem_05',\n",
       " 'poem_06',\n",
       " 'poem_07',\n",
       " 'poem_08',\n",
       " 'poem_09',\n",
       " 'poem_10']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spiders_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_expressions = [f\"\"\"\n",
    "################################################\n",
    "print('Starting Spider: {spider}')\n",
    "start = time_now()\n",
    "\n",
    "\n",
    "\n",
    "!scrapy crawl {spider} -o batch_{str(idx+1).zfill(2)}.json -L WARN --logfile scrapy_log.log\n",
    "\n",
    "logging.debug('Finished scraping BATCH {str(idx+1).zfill(2)} of {len(spiders_list)}')\n",
    "\n",
    "df_temp = pd.read_json('batch_{str(idx+1).zfill(2)}.json', encoding='utf-8')\n",
    "logging.debug(f'batch_{str(idx+1).zfill(2)}.json contains {{len(df_temp)}} observations')\n",
    "\n",
    "finish = time_now()\n",
    "\n",
    "duration = finish -  start\n",
    "logging.debug(f'Scraping Duration: {{round(duration.seconds / 60, 2)}} minutes')\n",
    "\n",
    "logging.debug('Transfering to Google Storage: batch_{str(idx+1).zfill(2)}.json ...')\n",
    "\n",
    "!gsutil cp  batch_{str(idx+1).zfill(2)}.json {gs_path}\n",
    "\n",
    "logging.debug('Finished transfering to Google Storage: batch_{str(idx+1).zfill(2)}.json')\n",
    "\n",
    "\n",
    "print('-'*50)\n",
    "\"\"\"\n",
    "for (idx, spider) in enumerate(spiders_list)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################################################\n",
      "print('Starting Spider: poem_01')\n",
      "start = time_now()\n",
      "\n",
      "\n",
      "\n",
      "!scrapy crawl poem_01 -o batch_01.json -L WARN --logfile scrapy_log.log\n",
      "\n",
      "logging.debug('Finished scraping BATCH 01 of 10')\n",
      "\n",
      "df_temp = pd.read_json('batch_01.json', encoding='utf-8')\n",
      "logging.debug(f'batch_01.json contains {len(df_temp)} observations')\n",
      "\n",
      "finish = time_now()\n",
      "\n",
      "duration = finish -  start\n",
      "logging.debug(f'Scraping Duration: {round(duration.seconds / 60, 2)} minutes')\n",
      "\n",
      "logging.debug('Transfering to Google Storage: batch_01.json ...')\n",
      "\n",
      "!gsutil cp  batch_01.json gs://sheikh-fitzgerald/ALDIWAN/DIWAN\n",
      "\n",
      "logging.debug('Finished transfering to Google Storage: batch_01.json')\n",
      "\n",
      "\n",
      "print('-'*50)\n",
      "\n",
      "\n",
      "################################################\n",
      "print('Starting Spider: poem_02')\n",
      "start = time_now()\n",
      "\n",
      "\n",
      "\n",
      "!scrapy crawl poem_02 -o batch_02.json -L WARN --logfile scrapy_log.log\n",
      "\n",
      "logging.debug('Finished scraping BATCH 02 of 10')\n",
      "\n",
      "df_temp = pd.read_json('batch_02.json', encoding='utf-8')\n",
      "logging.debug(f'batch_02.json contains {len(df_temp)} observations')\n",
      "\n",
      "finish = time_now()\n",
      "\n",
      "duration = finish -  start\n",
      "logging.debug(f'Scraping Duration: {round(duration.seconds / 60, 2)} minutes')\n",
      "\n",
      "logging.debug('Transfering to Google Storage: batch_02.json ...')\n",
      "\n",
      "!gsutil cp  batch_02.json gs://sheikh-fitzgerald/ALDIWAN/DIWAN\n",
      "\n",
      "logging.debug('Finished transfering to Google Storage: batch_02.json')\n",
      "\n",
      "\n",
      "print('-'*50)\n",
      "\n",
      "\n",
      "################################################\n",
      "print('Starting Spider: poem_03')\n",
      "start = time_now()\n",
      "\n",
      "\n",
      "\n",
      "!scrapy crawl poem_03 -o batch_03.json -L WARN --logfile scrapy_log.log\n",
      "\n",
      "logging.debug('Finished scraping BATCH 03 of 10')\n",
      "\n",
      "df_temp = pd.read_json('batch_03.json', encoding='utf-8')\n",
      "logging.debug(f'batch_03.json contains {len(df_temp)} observations')\n",
      "\n",
      "finish = time_now()\n",
      "\n",
      "duration = finish -  start\n",
      "logging.debug(f'Scraping Duration: {round(duration.seconds / 60, 2)} minutes')\n",
      "\n",
      "logging.debug('Transfering to Google Storage: batch_03.json ...')\n",
      "\n",
      "!gsutil cp  batch_03.json gs://sheikh-fitzgerald/ALDIWAN/DIWAN\n",
      "\n",
      "logging.debug('Finished transfering to Google Storage: batch_03.json')\n",
      "\n",
      "\n",
      "print('-'*50)\n",
      "\n",
      "\n",
      "################################################\n",
      "print('Starting Spider: poem_04')\n",
      "start = time_now()\n",
      "\n",
      "\n",
      "\n",
      "!scrapy crawl poem_04 -o batch_04.json -L WARN --logfile scrapy_log.log\n",
      "\n",
      "logging.debug('Finished scraping BATCH 04 of 10')\n",
      "\n",
      "df_temp = pd.read_json('batch_04.json', encoding='utf-8')\n",
      "logging.debug(f'batch_04.json contains {len(df_temp)} observations')\n",
      "\n",
      "finish = time_now()\n",
      "\n",
      "duration = finish -  start\n",
      "logging.debug(f'Scraping Duration: {round(duration.seconds / 60, 2)} minutes')\n",
      "\n",
      "logging.debug('Transfering to Google Storage: batch_04.json ...')\n",
      "\n",
      "!gsutil cp  batch_04.json gs://sheikh-fitzgerald/ALDIWAN/DIWAN\n",
      "\n",
      "logging.debug('Finished transfering to Google Storage: batch_04.json')\n",
      "\n",
      "\n",
      "print('-'*50)\n",
      "\n",
      "\n",
      "################################################\n",
      "print('Starting Spider: poem_05')\n",
      "start = time_now()\n",
      "\n",
      "\n",
      "\n",
      "!scrapy crawl poem_05 -o batch_05.json -L WARN --logfile scrapy_log.log\n",
      "\n",
      "logging.debug('Finished scraping BATCH 05 of 10')\n",
      "\n",
      "df_temp = pd.read_json('batch_05.json', encoding='utf-8')\n",
      "logging.debug(f'batch_05.json contains {len(df_temp)} observations')\n",
      "\n",
      "finish = time_now()\n",
      "\n",
      "duration = finish -  start\n",
      "logging.debug(f'Scraping Duration: {round(duration.seconds / 60, 2)} minutes')\n",
      "\n",
      "logging.debug('Transfering to Google Storage: batch_05.json ...')\n",
      "\n",
      "!gsutil cp  batch_05.json gs://sheikh-fitzgerald/ALDIWAN/DIWAN\n",
      "\n",
      "logging.debug('Finished transfering to Google Storage: batch_05.json')\n",
      "\n",
      "\n",
      "print('-'*50)\n",
      "\n",
      "\n",
      "################################################\n",
      "print('Starting Spider: poem_06')\n",
      "start = time_now()\n",
      "\n",
      "\n",
      "\n",
      "!scrapy crawl poem_06 -o batch_06.json -L WARN --logfile scrapy_log.log\n",
      "\n",
      "logging.debug('Finished scraping BATCH 06 of 10')\n",
      "\n",
      "df_temp = pd.read_json('batch_06.json', encoding='utf-8')\n",
      "logging.debug(f'batch_06.json contains {len(df_temp)} observations')\n",
      "\n",
      "finish = time_now()\n",
      "\n",
      "duration = finish -  start\n",
      "logging.debug(f'Scraping Duration: {round(duration.seconds / 60, 2)} minutes')\n",
      "\n",
      "logging.debug('Transfering to Google Storage: batch_06.json ...')\n",
      "\n",
      "!gsutil cp  batch_06.json gs://sheikh-fitzgerald/ALDIWAN/DIWAN\n",
      "\n",
      "logging.debug('Finished transfering to Google Storage: batch_06.json')\n",
      "\n",
      "\n",
      "print('-'*50)\n",
      "\n",
      "\n",
      "################################################\n",
      "print('Starting Spider: poem_07')\n",
      "start = time_now()\n",
      "\n",
      "\n",
      "\n",
      "!scrapy crawl poem_07 -o batch_07.json -L WARN --logfile scrapy_log.log\n",
      "\n",
      "logging.debug('Finished scraping BATCH 07 of 10')\n",
      "\n",
      "df_temp = pd.read_json('batch_07.json', encoding='utf-8')\n",
      "logging.debug(f'batch_07.json contains {len(df_temp)} observations')\n",
      "\n",
      "finish = time_now()\n",
      "\n",
      "duration = finish -  start\n",
      "logging.debug(f'Scraping Duration: {round(duration.seconds / 60, 2)} minutes')\n",
      "\n",
      "logging.debug('Transfering to Google Storage: batch_07.json ...')\n",
      "\n",
      "!gsutil cp  batch_07.json gs://sheikh-fitzgerald/ALDIWAN/DIWAN\n",
      "\n",
      "logging.debug('Finished transfering to Google Storage: batch_07.json')\n",
      "\n",
      "\n",
      "print('-'*50)\n",
      "\n",
      "\n",
      "################################################\n",
      "print('Starting Spider: poem_08')\n",
      "start = time_now()\n",
      "\n",
      "\n",
      "\n",
      "!scrapy crawl poem_08 -o batch_08.json -L WARN --logfile scrapy_log.log\n",
      "\n",
      "logging.debug('Finished scraping BATCH 08 of 10')\n",
      "\n",
      "df_temp = pd.read_json('batch_08.json', encoding='utf-8')\n",
      "logging.debug(f'batch_08.json contains {len(df_temp)} observations')\n",
      "\n",
      "finish = time_now()\n",
      "\n",
      "duration = finish -  start\n",
      "logging.debug(f'Scraping Duration: {round(duration.seconds / 60, 2)} minutes')\n",
      "\n",
      "logging.debug('Transfering to Google Storage: batch_08.json ...')\n",
      "\n",
      "!gsutil cp  batch_08.json gs://sheikh-fitzgerald/ALDIWAN/DIWAN\n",
      "\n",
      "logging.debug('Finished transfering to Google Storage: batch_08.json')\n",
      "\n",
      "\n",
      "print('-'*50)\n",
      "\n",
      "\n",
      "################################################\n",
      "print('Starting Spider: poem_09')\n",
      "start = time_now()\n",
      "\n",
      "\n",
      "\n",
      "!scrapy crawl poem_09 -o batch_09.json -L WARN --logfile scrapy_log.log\n",
      "\n",
      "logging.debug('Finished scraping BATCH 09 of 10')\n",
      "\n",
      "df_temp = pd.read_json('batch_09.json', encoding='utf-8')\n",
      "logging.debug(f'batch_09.json contains {len(df_temp)} observations')\n",
      "\n",
      "finish = time_now()\n",
      "\n",
      "duration = finish -  start\n",
      "logging.debug(f'Scraping Duration: {round(duration.seconds / 60, 2)} minutes')\n",
      "\n",
      "logging.debug('Transfering to Google Storage: batch_09.json ...')\n",
      "\n",
      "!gsutil cp  batch_09.json gs://sheikh-fitzgerald/ALDIWAN/DIWAN\n",
      "\n",
      "logging.debug('Finished transfering to Google Storage: batch_09.json')\n",
      "\n",
      "\n",
      "print('-'*50)\n",
      "\n",
      "\n",
      "################################################\n",
      "print('Starting Spider: poem_10')\n",
      "start = time_now()\n",
      "\n",
      "\n",
      "\n",
      "!scrapy crawl poem_10 -o batch_10.json -L WARN --logfile scrapy_log.log\n",
      "\n",
      "logging.debug('Finished scraping BATCH 10 of 10')\n",
      "\n",
      "df_temp = pd.read_json('batch_10.json', encoding='utf-8')\n",
      "logging.debug(f'batch_10.json contains {len(df_temp)} observations')\n",
      "\n",
      "finish = time_now()\n",
      "\n",
      "duration = finish -  start\n",
      "logging.debug(f'Scraping Duration: {round(duration.seconds / 60, 2)} minutes')\n",
      "\n",
      "logging.debug('Transfering to Google Storage: batch_10.json ...')\n",
      "\n",
      "!gsutil cp  batch_10.json gs://sheikh-fitzgerald/ALDIWAN/DIWAN\n",
      "\n",
      "logging.debug('Finished transfering to Google Storage: batch_10.json')\n",
      "\n",
      "\n",
      "print('-'*50)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in list_expressions:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spider: poem_01\n",
      "Current Time = 03:10:19.638461\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "print('Starting Spider: poem_01')\n",
    "start = time_now()\n",
    "\n",
    "\n",
    "\n",
    "!scrapy crawl poem_01 -o batch_01.json -L WARN --logfile scrapy_log.log\n",
    "\n",
    "logging.debug('Finished scraping BATCH 01 of 10')\n",
    "\n",
    "df_temp = pd.read_json('batch_01.json', encoding='utf-8')\n",
    "logging.debug(f'batch_01.json contains {len(df_temp)} observations')\n",
    "\n",
    "finish = time_now()\n",
    "\n",
    "duration = finish -  start\n",
    "logging.debug(f'Scraping Duration: {round(duration.seconds / 60, 2)} minutes')\n",
    "\n",
    "logging.debug('Transfering to Google Storage: batch_01.json ...')\n",
    "\n",
    "!gsutil cp  batch_01.json gs://sheikh-fitzgerald/ALDIWAN/DIWAN\n",
    "\n",
    "logging.debug('Finished transfering to Google Storage: batch_01.json')\n",
    "\n",
    "\n",
    "print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 03:18:53.451451\n",
      "Copying file://batch_02.json [Content-Type=application/json]...\n",
      "/ [1 files][ 17.2 MiB/ 17.2 MiB]                                                \n",
      "Operation completed over 1 objects/17.2 MiB.                                     \n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "print('Starting Spider: poem_02')\n",
    "start = time_now()\n",
    "\n",
    "\n",
    "\n",
    "!scrapy crawl poem_02 -o batch_02.json -L WARN --logfile scrapy_log.log\n",
    "\n",
    "logging.debug('Finished scraping BATCH 02 of 10')\n",
    "\n",
    "df_temp = pd.read_json('batch_02.json', encoding='utf-8')\n",
    "logging.debug(f'batch_02.json contains {len(df_temp)} observations')\n",
    "\n",
    "finish = time_now()\n",
    "\n",
    "duration = finish -  start\n",
    "logging.debug(f'Scraping Duration: {round(duration.seconds / 60, 2)} minutes')\n",
    "\n",
    "logging.debug('Transfering to Google Storage: batch_02.json ...')\n",
    "\n",
    "!gsutil cp  batch_02.json gs://sheikh-fitzgerald/ALDIWAN/DIWAN\n",
    "\n",
    "logging.debug('Finished transfering to Google Storage: batch_02.json')\n",
    "\n",
    "\n",
    "print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spider: poem_03\n",
      "Current Time = 03:18:55.688259\n",
      "Current Time = 03:23:16.672806\n",
      "Copying file://batch_03.json [Content-Type=application/json]...\n",
      "/ [1 files][ 13.8 MiB/ 13.8 MiB]                                                \n",
      "Operation completed over 1 objects/13.8 MiB.                                     \n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "print('Starting Spider: poem_03')\n",
    "start = time_now()\n",
    "\n",
    "\n",
    "\n",
    "!scrapy crawl poem_03 -o batch_03.json -L WARN --logfile scrapy_log.log\n",
    "\n",
    "logging.debug('Finished scraping BATCH 03 of 10')\n",
    "\n",
    "df_temp = pd.read_json('batch_03.json', encoding='utf-8')\n",
    "logging.debug(f'batch_03.json contains {len(df_temp)} observations')\n",
    "\n",
    "finish = time_now()\n",
    "\n",
    "duration = finish -  start\n",
    "logging.debug(f'Scraping Duration: {round(duration.seconds / 60, 2)} minutes')\n",
    "\n",
    "logging.debug('Transfering to Google Storage: batch_03.json ...')\n",
    "\n",
    "!gsutil cp  batch_03.json gs://sheikh-fitzgerald/ALDIWAN/DIWAN\n",
    "\n",
    "logging.debug('Finished transfering to Google Storage: batch_03.json')\n",
    "\n",
    "\n",
    "print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spider: poem_04\n",
      "Current Time = 03:23:18.825267\n",
      "Current Time = 03:27:27.872114\n",
      "Copying file://batch_04.json [Content-Type=application/json]...\n",
      "/ [1 files][ 19.7 MiB/ 19.7 MiB]                                                \n",
      "Operation completed over 1 objects/19.7 MiB.                                     \n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "print('Starting Spider: poem_04')\n",
    "start = time_now()\n",
    "\n",
    "\n",
    "\n",
    "!scrapy crawl poem_04 -o batch_04.json -L WARN --logfile scrapy_log.log\n",
    "\n",
    "logging.debug('Finished scraping BATCH 04 of 10')\n",
    "\n",
    "df_temp = pd.read_json('batch_04.json', encoding='utf-8')\n",
    "logging.debug(f'batch_04.json contains {len(df_temp)} observations')\n",
    "\n",
    "finish = time_now()\n",
    "\n",
    "duration = finish -  start\n",
    "logging.debug(f'Scraping Duration: {round(duration.seconds / 60, 2)} minutes')\n",
    "\n",
    "logging.debug('Transfering to Google Storage: batch_04.json ...')\n",
    "\n",
    "!gsutil cp  batch_04.json gs://sheikh-fitzgerald/ALDIWAN/DIWAN\n",
    "\n",
    "logging.debug('Finished transfering to Google Storage: batch_04.json')\n",
    "\n",
    "\n",
    "print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spider: poem_05\n",
      "Current Time = 03:27:30.143233\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "print('Starting Spider: poem_05')\n",
    "start = time_now()\n",
    "\n",
    "\n",
    "\n",
    "!scrapy crawl poem_05 -o batch_05.json -L WARN --logfile scrapy_log.log\n",
    "\n",
    "logging.debug('Finished scraping BATCH 05 of 10')\n",
    "\n",
    "df_temp = pd.read_json('batch_05.json', encoding='utf-8')\n",
    "logging.debug(f'batch_05.json contains {len(df_temp)} observations')\n",
    "\n",
    "finish = time_now()\n",
    "\n",
    "duration = finish -  start\n",
    "logging.debug(f'Scraping Duration: {round(duration.seconds / 60, 2)} minutes')\n",
    "\n",
    "logging.debug('Transfering to Google Storage: batch_05.json ...')\n",
    "\n",
    "!gsutil cp  batch_05.json gs://sheikh-fitzgerald/ALDIWAN/DIWAN\n",
    "\n",
    "logging.debug('Finished transfering to Google Storage: batch_05.json')\n",
    "\n",
    "\n",
    "print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 03:35:56.001156\n",
      "Copying file://batch_06.json [Content-Type=application/json]...\n",
      "/ [1 files][ 18.6 MiB/ 18.6 MiB]                                                \n",
      "Operation completed over 1 objects/18.6 MiB.                                     \n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "print('Starting Spider: poem_06')\n",
    "start = time_now()\n",
    "\n",
    "\n",
    "\n",
    "!scrapy crawl poem_06 -o batch_06.json -L WARN --logfile scrapy_log.log\n",
    "\n",
    "logging.debug('Finished scraping BATCH 06 of 10')\n",
    "\n",
    "df_temp = pd.read_json('batch_06.json', encoding='utf-8')\n",
    "logging.debug(f'batch_06.json contains {len(df_temp)} observations')\n",
    "\n",
    "finish = time_now()\n",
    "\n",
    "duration = finish -  start\n",
    "logging.debug(f'Scraping Duration: {round(duration.seconds / 60, 2)} minutes')\n",
    "\n",
    "logging.debug('Transfering to Google Storage: batch_06.json ...')\n",
    "\n",
    "!gsutil cp  batch_06.json gs://sheikh-fitzgerald/ALDIWAN/DIWAN\n",
    "\n",
    "logging.debug('Finished transfering to Google Storage: batch_06.json')\n",
    "\n",
    "\n",
    "print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spider: poem_07\n",
      "Current Time = 03:35:58.226137\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "print('Starting Spider: poem_07')\n",
    "start = time_now()\n",
    "\n",
    "\n",
    "\n",
    "!scrapy crawl poem_07 -o batch_07.json -L WARN --logfile scrapy_log.log\n",
    "\n",
    "logging.debug('Finished scraping BATCH 07 of 10')\n",
    "\n",
    "df_temp = pd.read_json('batch_07.json', encoding='utf-8')\n",
    "logging.debug(f'batch_07.json contains {len(df_temp)} observations')\n",
    "\n",
    "finish = time_now()\n",
    "\n",
    "duration = finish -  start\n",
    "logging.debug(f'Scraping Duration: {round(duration.seconds / 60, 2)} minutes')\n",
    "\n",
    "logging.debug('Transfering to Google Storage: batch_07.json ...')\n",
    "\n",
    "!gsutil cp  batch_07.json gs://sheikh-fitzgerald/ALDIWAN/DIWAN\n",
    "\n",
    "logging.debug('Finished transfering to Google Storage: batch_07.json')\n",
    "\n",
    "\n",
    "print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 03:44:21.555229\n",
      "Copying file://batch_08.json [Content-Type=application/json]...\n",
      "/ [1 files][ 16.3 MiB/ 16.3 MiB]                                                \n",
      "Operation completed over 1 objects/16.3 MiB.                                     \n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "print('Starting Spider: poem_08')\n",
    "start = time_now()\n",
    "\n",
    "\n",
    "\n",
    "!scrapy crawl poem_08 -o batch_08.json -L WARN --logfile scrapy_log.log\n",
    "\n",
    "logging.debug('Finished scraping BATCH 08 of 10')\n",
    "\n",
    "df_temp = pd.read_json('batch_08.json', encoding='utf-8')\n",
    "logging.debug(f'batch_08.json contains {len(df_temp)} observations')\n",
    "\n",
    "finish = time_now()\n",
    "\n",
    "duration = finish -  start\n",
    "logging.debug(f'Scraping Duration: {round(duration.seconds / 60, 2)} minutes')\n",
    "\n",
    "logging.debug('Transfering to Google Storage: batch_08.json ...')\n",
    "\n",
    "!gsutil cp  batch_08.json gs://sheikh-fitzgerald/ALDIWAN/DIWAN\n",
    "\n",
    "logging.debug('Finished transfering to Google Storage: batch_08.json')\n",
    "\n",
    "\n",
    "print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spider: poem_09\n",
      "Current Time = 03:44:23.784730\n",
      "Current Time = 03:48:16.899242\n",
      "Copying file://batch_09.json [Content-Type=application/json]...\n",
      "/ [1 files][ 14.9 MiB/ 14.9 MiB]                                                \n",
      "Operation completed over 1 objects/14.9 MiB.                                     \n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "print('Starting Spider: poem_09')\n",
    "start = time_now()\n",
    "\n",
    "\n",
    "\n",
    "!scrapy crawl poem_09 -o batch_09.json -L WARN --logfile scrapy_log.log\n",
    "\n",
    "logging.debug('Finished scraping BATCH 09 of 10')\n",
    "\n",
    "df_temp = pd.read_json('batch_09.json', encoding='utf-8')\n",
    "logging.debug(f'batch_09.json contains {len(df_temp)} observations')\n",
    "\n",
    "finish = time_now()\n",
    "\n",
    "duration = finish -  start\n",
    "logging.debug(f'Scraping Duration: {round(duration.seconds / 60, 2)} minutes')\n",
    "\n",
    "logging.debug('Transfering to Google Storage: batch_09.json ...')\n",
    "\n",
    "!gsutil cp  batch_09.json gs://sheikh-fitzgerald/ALDIWAN/DIWAN\n",
    "\n",
    "logging.debug('Finished transfering to Google Storage: batch_09.json')\n",
    "\n",
    "\n",
    "print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spider: poem_10\n",
      "Current Time = 03:48:19.106311\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "print('Starting Spider: poem_10')\n",
    "start = time_now()\n",
    "\n",
    "\n",
    "\n",
    "!scrapy crawl poem_10 -o batch_10.json -L WARN --logfile scrapy_log.log\n",
    "\n",
    "logging.debug('Finished scraping BATCH 10 of 10')\n",
    "\n",
    "df_temp = pd.read_json('batch_10.json', encoding='utf-8')\n",
    "logging.debug(f'batch_10.json contains {len(df_temp)} observations')\n",
    "\n",
    "finish = time_now()\n",
    "\n",
    "duration = finish -  start\n",
    "logging.debug(f'Scraping Duration: {round(duration.seconds / 60, 2)} minutes')\n",
    "\n",
    "logging.debug('Transfering to Google Storage: batch_10.json ...')\n",
    "\n",
    "!gsutil cp  batch_10.json gs://sheikh-fitzgerald/ALDIWAN/DIWAN\n",
    "\n",
    "logging.debug('Finished transfering to Google Storage: batch_10.json')\n",
    "\n",
    "\n",
    "print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
