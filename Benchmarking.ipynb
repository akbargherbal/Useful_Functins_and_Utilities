{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CnYyjyOEQzb",
        "outputId": "7c971acc-5d73-4289-96b4-430d125fc162"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "08:23:33\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "def get_current_time():\n",
        "    \"\"\"\n",
        "    Get the current time in the format HH:MM:SS.\n",
        "    \"\"\"\n",
        "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
        "    return current_time\n",
        "\n",
        "def calculate_time_difference(start_time, end_time):\n",
        "    \"\"\"\n",
        "    Calculate the duration between two times in minutes.\n",
        "\n",
        "    Parameters:\n",
        "    - start_time (str): Start time in the format HH:MM:SS.\n",
        "    - end_time (str): End time in the format HH:MM:SS.\n",
        "\n",
        "    Returns:\n",
        "    - int: Duration in minutes.\n",
        "    \"\"\"\n",
        "    # Convert time strings to datetime objects\n",
        "    start_datetime = datetime.strptime(start_time, \"%H:%M:%S\")\n",
        "    end_datetime = datetime.strptime(end_time, \"%H:%M:%S\")\n",
        "\n",
        "    # Calculate the duration in minutes\n",
        "    duration_minutes = (end_datetime - start_datetime).total_seconds() / 60\n",
        "\n",
        "    return duration_minutes\n",
        "\n",
        "# Example usage:\n",
        "\n",
        "\n",
        "start_time = get_current_time()\n",
        "print(start_time)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZXVz6Tr5yvt",
        "outputId": "ed8e0a9f-e7e8-418c-c295-dd37ec02bd8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of CPU cores: 2\n",
            "Total RAM: 12.67 GB\n",
            "Available RAM: 11.72 GB\n",
            "GPU: No GPU available\n",
            "No GPU\n"
          ]
        }
      ],
      "source": [
        "import psutil\n",
        "import os\n",
        "\n",
        "# Number of CPU cores\n",
        "cpu_cores = os.cpu_count()\n",
        "\n",
        "# Memory (RAM) information\n",
        "ram_info = psutil.virtual_memory()\n",
        "total_ram = ram_info.total\n",
        "available_ram = ram_info.available\n",
        "\n",
        "# GPU information (if available)\n",
        "try:\n",
        "    from tensorflow.python.client import device_lib\n",
        "\n",
        "    devices = device_lib.list_local_devices()\n",
        "    gpu_info = [device for device in devices if device.device_type == 'GPU']\n",
        "    if gpu_info:\n",
        "        gpu_name = gpu_info[0].name\n",
        "\n",
        "        try:\n",
        "          gpu_name_human = devices[1].physical_device_desc\n",
        "        except:\n",
        "          gpu_name_human = \"No GPU available\"\n",
        "\n",
        "\n",
        "    else:\n",
        "        gpu_name = \"No GPU available\"\n",
        "\n",
        "except ImportError:\n",
        "    gpu_name = \"TensorFlow not installed\"\n",
        "\n",
        "# Print the information\n",
        "print(f\"Number of CPU cores: {cpu_cores}\")\n",
        "print(f\"Total RAM: {total_ram / (1024 ** 3):.2f} GB\")\n",
        "print(f\"Available RAM: {available_ram / (1024 ** 3):.2f} GB\")\n",
        "print(f\"GPU: {gpu_name}\")\n",
        "try:\n",
        "  print(f\"GPU: {gpu_name_human}\")\n",
        "except:\n",
        "  print(f\"No GPU\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PrABott61Ad"
      },
      "outputs": [],
      "source": [
        "benchmark = '''\n",
        "\n",
        "Number of CPU cores: 8\n",
        "Total RAM: 50.99 GB\n",
        "Available RAM: 49.85 GB\n",
        "GPU: No GPU available\n",
        "No GPU\n",
        "Usage rate: approximately 0.12 per hour\n",
        "\n",
        "\n",
        "Number of CPU cores: 8\n",
        "Total RAM: 50.99 GB\n",
        "Available RAM: 49.72 GB\n",
        "GPU: /device:GPU:0\n",
        "GPU: device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\n",
        "Usage rate: approximately 5.45 per hour\n",
        "\n",
        "\n",
        "Number of CPU cores: 8\n",
        "Total RAM: 50.99 GB\n",
        "Available RAM: 49.74 GB\n",
        "GPU: /device:GPU:0\n",
        "GPU: device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
        "Usage rate: approximately 2.05 per hour\n",
        "\n",
        "\n",
        "'''.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhPPv8E97Qev",
        "outputId": "19f37910-4819-4af6-fef5-5dc6a5220cab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of CPU cores: 8\n",
            "Total RAM: 50.99 GB\n",
            "Available RAM: 49.85 GB\n",
            "GPU: No GPU available\n",
            "No GPU\n",
            "Usage rate: approximately 0.12 per hour\n",
            "\n",
            "\n",
            "Number of CPU cores: 8\n",
            "Total RAM: 50.99 GB\n",
            "Available RAM: 49.72 GB\n",
            "GPU: /device:GPU:0\n",
            "GPU: device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\n",
            "Usage rate: approximately 5.45 per hour\n",
            "\n",
            "\n",
            "Number of CPU cores: 8\n",
            "Total RAM: 50.99 GB\n",
            "Available RAM: 49.74 GB\n",
            "GPU: /device:GPU:0\n",
            "GPU: device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "Usage rate: approximately 2.05 per hour\n"
          ]
        }
      ],
      "source": [
        "print(benchmark)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zBpX2cxuBEUr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b139424e-ca1a-4acf-8ba4-d00727734faa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duration between 08:23:33 and 08:23:51: 0.3 minutes\n"
          ]
        }
      ],
      "source": [
        "end_time = get_current_time()\n",
        "\n",
        "duration = calculate_time_difference(start_time, end_time)\n",
        "print(f\"Duration between {start_time} and {end_time}: {duration} minutes\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ccw1mtkfErmb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}