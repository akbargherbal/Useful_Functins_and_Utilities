{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "Current Time = 17:22:05.119624\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "def time_now():\n",
    "    '''Get Current Time'''\n",
    "    \n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S.%f\")\n",
    "    print(\"Current Time =\", current_time)\n",
    "    return now\n",
    "\n",
    "\n",
    "############\n",
    "print('Starting...')\n",
    "start = time_now()\n",
    "############\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_list = ['#', '’', \"'\"  '!',  ',',  '(',  '.',  '‡',  '9',  '*',  '2',  ']',  '†',  '1',  '\"',  '/',  '5',  '4',  '0',  ';',  '¾',  '‘',  '¼',  '{',  ')',  '…',  '½',  '6',  '×',  '[',  '+',  ':',  '$',  '3',  '?',  '7',  '©',  '’',  '£',  '8']\n",
    "\n",
    "pat_verb_noun_phrase =[\n",
    "    {'POS': {'IN': 'VERB ADV'.split()}, 'OP':'+'}, \n",
    "    {'POS': {'IN' : 'DET ADP PART PRON'.split()}, 'OP':'*'},\n",
    "    {'POS': {'IN': 'NOUN ADJ PROPN'.split()}, 'OP':'+'}\n",
    "]\n",
    "\n",
    "\n",
    "pat_noun_verb_phrase = [\n",
    "            {'POS': {'IN': ['NOUN', 'ADJ']}, 'OP': '+'},\n",
    "            {'POS': {'IN': ['AUX', 'PART', 'ADP']}, 'OP': '*'},\n",
    "            {'POS': {'IN': ['VERB', 'ADV']}, 'OP': '+'}\n",
    "            ]\n",
    "            \n",
    "            \n",
    "\n",
    "pat_n_p_v = [\n",
    "            {'POS': {'IN': ['NOUN', 'ADJ', 'PROPN']}, 'OP': '+'},\n",
    "            {'POS': {'IN': ['PUNCT', 'CCONJ']}, 'LEMMA': {'NOT_IN': ignore_list}, 'OP': '+'},\n",
    "            {'POS': {'IN': ['NOUN', 'ADJ', 'VERB', 'PROPN']}, 'OP':'+'}\n",
    "             ]            \n",
    "             \n",
    "pat_noun = [\n",
    "    {'POS': {'IN': 'NOUN ADJ PROPN'.split()} , 'OP':'+'}\n",
    "                        ]\n",
    "\n",
    "pat_n_n = [\n",
    "    {'POS': {'IN': ['NOUN', 'ADJ', 'PROPN']}, 'OP': '+'},\n",
    "    {'POS': {'IN': ['DET', 'ADP', 'PART']}, 'OP': '+'},\n",
    "    {'POS': {'IN': ['NOUN', 'ADJ', 'PROPN']}, 'OP': '+'}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_pos_patterns = [i for i in dir() if i.startswith('pat_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter threhold per pattern per batch:   2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Threshold is 2\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    threshold_pattern = int(input('''\n",
    "Enter threhold per pattern per batch:  '''))\n",
    "    print(f\"\"\"\n",
    "Threshold is {threshold_pattern}\n",
    "    \"\"\")\n",
    "except:\n",
    "    print('Threshold must be an integer number; 2 was chosen for you')\n",
    "    threshold_pattern = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_lemma_pattern(doc, pat_name='anything', pat_collection='list_of_dictionaries'):\n",
    "    '''\n",
    "    Given a spacy doc object; find the span according to the pattern given.\n",
    "    ''' \n",
    "    matcher =  Matcher(vocab = nlp.vocab)\n",
    "    matcher.add(f'{pat_name}', pat_collection, greedy='LONGEST')\n",
    "    \n",
    "    \n",
    "    doc_match = matcher(doc)\n",
    "    \n",
    "    \n",
    "    list_container = []\n",
    "    for match in doc_match:\n",
    "        start = match[1]\n",
    "        end = match[2]\n",
    "        \n",
    "        result_lemma = doc[start:end]\n",
    "        result_lemma = [(i.lemma_ + i.whitespace_) for i in result_lemma] # new!\n",
    "        result_lemma = ''.join(result_lemma).strip()\n",
    "\n",
    "        result_token = doc[start:end]\n",
    "        result_token = [(i.text + i.whitespace_) for i in result_token] # new!\n",
    "        result_token = ''.join(result_token).strip()\n",
    "\n",
    "        result_pos = doc[start:end]\n",
    "        result_pos = [i.pos_ for i in result_pos] # new!\n",
    "        result_pos = ' '.join(result_pos).strip()\n",
    "        \n",
    "        if len(result_lemma.split()) > 1:\n",
    "            list_container.append((result_token, result_lemma, result_pos))\n",
    "\n",
    "    return list_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.mkdir('IOC_GENERAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for root, dirs, files in os.walk('NLP/'):\n",
    "#     files = sorted(files)\n",
    "#     files_path = [os.path.join(root, file) for file in files if file.endswith('.pkl')]\n",
    "#     files_path = [f'./{file}' for file in files_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_path = ['IOC_news_text.pkl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing IOC_news_text.pkl Batch 1 of 1\n",
      "Starting NLP\n",
      "Current Time = 17:36:25.026660\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d54ac755f29441628f44c4e2e8d2996f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/480405 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 18:57:12.310858\n",
      "Finished NLP\n",
      "Total NLP Duration: 80.78333333333333 minutes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ceca5dde5f843cfa1b47c07d454bac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/480405 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c581fee83064fafbdc3f1b5f6f6b1be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/512797 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08d4e3bf72644b8b8afb1803f5139c11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/480405 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a464e84b9eb94393a91b5f79ee7fb5b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/153760 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c646931811d74cd5a6181707ec421c50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/480405 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48070a1242ca4d0f95c3d1299dd9eacf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/1039238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "462e950f31814a2d963cd2bd5f56d6f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/480405 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "059d48206c6e4d7eaf91db68c30b8176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/371623 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd7b8678b27a427580ab8400f12c9a9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/480405 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64ee1439f4f5495290d112ffe0642f6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/892200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished IOC_news_text.pkl Batch 1 of 1\n"
     ]
    }
   ],
   "source": [
    "for (idx, file) in enumerate(files_path):\n",
    "    print(f'Processing {file} Batch {idx+1} of {len(files_path)}')\n",
    "\n",
    "    df_temp = pd.read_pickle(file)\n",
    "    \n",
    "    \n",
    "    print('Starting NLP')\n",
    "    \n",
    "    start_nlp = time_now()\n",
    "    df_temp['NLP'] = df_temp['TEXT'].swifter.apply(lambda x: nlp(x))\n",
    "    \n",
    "    finish_nlp = time_now()\n",
    "    print('Finished NLP')\n",
    "    duration  = ((finish_nlp - start_nlp).seconds)/60\n",
    "    print(f'Total NLP Duration: {duration} minutes')\n",
    "    \n",
    "    for pat in list_pos_patterns:\n",
    "        pattern_name = pat.upper()\n",
    "        df_temp[pattern_name] = df_temp['NLP'].swifter.apply(lambda x: get_pos_lemma_pattern(x, f'{pat}', [eval(pat)]))\n",
    "        \n",
    "        list_pat = list(chain(*df_temp[pattern_name]))\n",
    "        df_pattern  = pd.DataFrame(data=list_pat)\n",
    "        df_pattern = df_pattern.rename(columns={0: 'TEXT', 1: 'LEMMA', 2: 'POS'})\n",
    "        \n",
    "        dict_pattern = dict(df_pattern['LEMMA'].value_counts())\n",
    "        dict_pattern = {k:v for k,v in dict_pattern.items() if v >= threshold_pattern}\n",
    "        \n",
    "        df_pattern = df_pattern[df_pattern['LEMMA'].swifter.apply(lambda x: x in dict_pattern)].reset_index(drop=True)\n",
    "        df_pattern.to_pickle(F'./IOC_GENERAL/BATCH_{str(idx+1).zfill(2)}_{pattern_name}.pkl', protocol=4)\n",
    "    print(f'Finished {file} Batch {idx+1} of {len(files_path)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_pickle('OUTPUT_GENDER/BATCH_01_PAT_N_N.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['LEMMA'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>LEMMA</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>provide the highlight</td>\n",
       "      <td>provide the highlight</td>\n",
       "      <td>VERB DET NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>struck gold</td>\n",
       "      <td>strike gold</td>\n",
       "      <td>VERB NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>produced a late burst</td>\n",
       "      <td>produce a late burst</td>\n",
       "      <td>VERB DET ADJ NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>assured of silver</td>\n",
       "      <td>assure of silver</td>\n",
       "      <td>VERB ADP NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>secure bronze</td>\n",
       "      <td>secure bronze</td>\n",
       "      <td>VERB NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456830</th>\n",
       "      <td>win the next</td>\n",
       "      <td>win the next</td>\n",
       "      <td>VERB DET ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456831</th>\n",
       "      <td>turned the tide</td>\n",
       "      <td>turn the tide</td>\n",
       "      <td>VERB DET NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456832</th>\n",
       "      <td>exhausting rallies</td>\n",
       "      <td>exhaust rally</td>\n",
       "      <td>VERB NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456833</th>\n",
       "      <td>reigning Olympic champion Viktor Axelsen</td>\n",
       "      <td>reign olympic champion Viktor Axelsen</td>\n",
       "      <td>VERB ADJ NOUN PROPN PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456834</th>\n",
       "      <td>singles semis</td>\n",
       "      <td>single semis</td>\n",
       "      <td>VERB PROPN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>456835 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            TEXT  \\\n",
       "0                          provide the highlight   \n",
       "1                                    struck gold   \n",
       "2                          produced a late burst   \n",
       "3                              assured of silver   \n",
       "4                                  secure bronze   \n",
       "...                                          ...   \n",
       "456830                              win the next   \n",
       "456831                           turned the tide   \n",
       "456832                        exhausting rallies   \n",
       "456833  reigning Olympic champion Viktor Axelsen   \n",
       "456834                             singles semis   \n",
       "\n",
       "                                        LEMMA                        POS  \n",
       "0                       provide the highlight              VERB DET NOUN  \n",
       "1                                 strike gold                  VERB NOUN  \n",
       "2                        produce a late burst          VERB DET ADJ NOUN  \n",
       "3                            assure of silver              VERB ADP NOUN  \n",
       "4                               secure bronze                  VERB NOUN  \n",
       "...                                       ...                        ...  \n",
       "456830                           win the next               VERB DET ADJ  \n",
       "456831                          turn the tide              VERB DET NOUN  \n",
       "456832                          exhaust rally                  VERB NOUN  \n",
       "456833  reign olympic champion Viktor Axelsen  VERB ADJ NOUN PROPN PROPN  \n",
       "456834                           single semis                 VERB PROPN  \n",
       "\n",
       "[456835 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_verbs_gen = dict(Counter(list(chain(*df_temp.NLP.apply(lambda x: [i.lemma_ for i in x if i.pos_ == 'VERB'])))).most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_nouns_gen = dict(Counter(list(chain(*df_temp.NLP.apply(lambda x: [i.lemma_ for i in x if i.pos_ == 'NOUN'])))).most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_adj_gen = dict(Counter(list(chain(*df_temp.NLP.apply(lambda x: [i.lemma_ for i in x if i.pos_ == 'ADJ'])))).most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_adv_gen = dict(Counter(list(chain(*df_temp.NLP.apply(lambda x: [i.lemma_ for i in x if i.pos_ == 'ADV'])))).most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data = dict_adj_gen.items()).rename(columns={0: 'WORD', 1:'FREQ' }).to_pickle('IOC_GENERAL_ADJECTIVES.pkl', protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data = dict_adv_gen.items()).rename(columns={0: 'WORD', 1:'FREQ' }).to_pickle('IOC_GENERAL_ADVERBS.pkl', protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data = dict_nouns_gen.items()).rename(columns={0: 'WORD', 1:'FREQ' }).to_pickle('IOC_GENERAL_NOUNS.pkl', protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data = dict_verbs_gen.items()).rename(columns={0: 'WORD', 1:'FREQ' }).to_pickle('IOC_GENERAL_VERBS.pkl', protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>LEMMA</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>late burst to secure</td>\n",
       "      <td>late burst to secure</td>\n",
       "      <td>ADJ NOUN PART VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>silver already</td>\n",
       "      <td>silver already</td>\n",
       "      <td>NOUN ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bronze ahead</td>\n",
       "      <td>bronze ahead</td>\n",
       "      <td>NOUN ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Indian shooters had managed</td>\n",
       "      <td>indian shooter have manage</td>\n",
       "      <td>ADJ NOUN AUX VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unable to participate</td>\n",
       "      <td>unable to participate</td>\n",
       "      <td>ADJ PART VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170174</th>\n",
       "      <td>play resumed</td>\n",
       "      <td>play resume</td>\n",
       "      <td>NOUN VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170175</th>\n",
       "      <td>title shot</td>\n",
       "      <td>title shoot</td>\n",
       "      <td>NOUN VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170176</th>\n",
       "      <td>players went</td>\n",
       "      <td>player go</td>\n",
       "      <td>NOUN VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170177</th>\n",
       "      <td>guns blazing</td>\n",
       "      <td>gun blaze</td>\n",
       "      <td>NOUN VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170178</th>\n",
       "      <td>men’s singles</td>\n",
       "      <td>man’s single</td>\n",
       "      <td>NOUN PART VERB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170179 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               TEXT                       LEMMA  \\\n",
       "0              late burst to secure        late burst to secure   \n",
       "1                    silver already              silver already   \n",
       "2                      bronze ahead                bronze ahead   \n",
       "3       Indian shooters had managed  indian shooter have manage   \n",
       "4             unable to participate       unable to participate   \n",
       "...                             ...                         ...   \n",
       "170174                 play resumed                 play resume   \n",
       "170175                   title shot                 title shoot   \n",
       "170176                 players went                   player go   \n",
       "170177                 guns blazing                   gun blaze   \n",
       "170178                men’s singles                man’s single   \n",
       "\n",
       "                       POS  \n",
       "0       ADJ NOUN PART VERB  \n",
       "1                 NOUN ADV  \n",
       "2                 NOUN ADV  \n",
       "3        ADJ NOUN AUX VERB  \n",
       "4            ADJ PART VERB  \n",
       "...                    ...  \n",
       "170174           NOUN VERB  \n",
       "170175           NOUN VERB  \n",
       "170176           NOUN VERB  \n",
       "170177           NOUN VERB  \n",
       "170178      NOUN PART VERB  \n",
       "\n",
       "[170179 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_pickle('IOC_GENERAL/BATCH_01_PAT_NOUN_VERB_PHRASE.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 12] Cannot allocate memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15330/41200415.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'zip -r IOC_GENERAL.zip IOC_GENERAL/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ipykernel/zmqshell.py\u001b[0m in \u001b[0;36msystem_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_exit_code\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_exit_code\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[0;31m# Ensure new system_piped implementation is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/utils/_process_posix.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0mchild\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpexpect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawnb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'-c'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Pexpect-U\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                 \u001b[0mchild\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpexpect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'-c'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Vanilla Pexpect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m             \u001b[0mflush\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, command, args, timeout, maxread, searchwindowsize, logfile, cwd, env, ignore_sighup, echo, preexec_fn, encoding, codec_errors, dimensions, use_poll)\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'<pexpect factory incomplete>'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreexec_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_poll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_poll\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36m_spawn\u001b[0;34m(self, command, args, preexec_fn, dimensions)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         self.ptyproc = self._spawnpty(self.args, env=self.env,\n\u001b[0;32m--> 304\u001b[0;31m                                      cwd=self.cwd, **kwargs)\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mptyproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36m_spawnpty\u001b[0;34m(self, args, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_spawnpty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;34m'''Spawn a pty and return an instance of PtyProcess.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mptyprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPtyProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ptyprocess/ptyprocess.py\u001b[0m in \u001b[0;36mspawn\u001b[0;34m(cls, argv, cwd, env, echo, preexec_fn, dimensions, pass_fds)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_native_pty_fork\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m             \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;31m# Use internal fork_pty, for Solaris\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/pty.py\u001b[0m in \u001b[0;36mfork\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mmaster_fd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslave_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenpty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mCHILD\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;31m# Establish a new session.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 12] Cannot allocate memory"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m97",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m97"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
