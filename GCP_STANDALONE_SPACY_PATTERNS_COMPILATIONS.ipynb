{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "Current Time = 21:47:57.001260\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "def time_now():\n",
    "    '''Get Current Time'''\n",
    "    \n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S.%f\")\n",
    "    print(\"Current Time =\", current_time)\n",
    "    return now\n",
    "\n",
    "\n",
    "############\n",
    "print('Starting...')\n",
    "start = time_now()\n",
    "############\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_list = ['#', '’', \"'\"  '!',  ',',  '(',  '.',  '‡',  '9',  '*',  '2',  ']',  '†',  '1',  '\"',  '/',  '5',  '4',  '0',  ';',  '¾',  '‘',  '¼',  '{',  ')',  '…',  '½',  '6',  '×',  '[',  '+',  ':',  '$',  '3',  '?',  '7',  '©',  '’',  '£',  '8']\n",
    "\n",
    "pat_verb_noun_phrase =[\n",
    "    {'POS': {'IN': 'VERB ADV'.split()}, 'OP':'+'}, \n",
    "    {'POS': {'IN' : 'DET ADP PART PRON'.split()}, 'OP':'*'},\n",
    "    {'POS': {'IN': 'NOUN ADJ PROPN'.split()}, 'OP':'+'}\n",
    "]\n",
    "\n",
    "\n",
    "pat_noun_verb_phrase = [\n",
    "            {'POS': {'IN': ['NOUN', 'ADJ']}, 'OP': '+'},\n",
    "            {'POS': {'IN': ['AUX', 'PART', 'ADP']}, 'OP': '*'},\n",
    "            {'POS': {'IN': ['VERB', 'ADV']}, 'OP': '+'}\n",
    "            ]\n",
    "            \n",
    "            \n",
    "\n",
    "pat_n_p_v = [\n",
    "            {'POS': {'IN': ['NOUN', 'ADJ', 'PROPN']}, 'OP': '+'},\n",
    "            {'POS': {'IN': ['PUNCT', 'CCONJ']}, 'LEMMA': {'NOT_IN': ignore_list}, 'OP': '+'},\n",
    "            {'POS': {'IN': ['NOUN', 'ADJ', 'VERB', 'PROPN']}, 'OP':'+'}\n",
    "             ]            \n",
    "             \n",
    "pat_noun = [\n",
    "    {'POS': {'IN': 'NOUN ADJ PROPN'.split()} , 'OP':'+'}\n",
    "                        ]\n",
    "\n",
    "pat_n_n = [\n",
    "    {'POS': {'IN': ['NOUN', 'ADJ', 'PROPN']}, 'OP': '+'},\n",
    "    {'POS': {'IN': ['DET', 'ADP', 'PART']}, 'OP': '+'},\n",
    "    {'POS': {'IN': ['NOUN', 'ADJ', 'PROPN']}, 'OP': '+'}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_pos_patterns = [i for i in dir() if i.startswith('pat_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter threhold per pattern per batch:   4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Threshold is 4\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    threshold_pattern = int(input('''\n",
    "Enter threhold per pattern per batch:  '''))\n",
    "    print(f\"\"\"\n",
    "Threshold is {threshold_pattern}\n",
    "    \"\"\")\n",
    "except:\n",
    "    print('Threshold must be an integer number; 2 was chosen for you')\n",
    "    threshold_pattern = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_lemma_pattern(doc, pat_name='anything', pat_collection='list_of_dictionaries'):\n",
    "    '''\n",
    "    Given a spacy doc object; find the span according to the pattern given.\n",
    "    ''' \n",
    "    matcher =  Matcher(vocab = nlp.vocab)\n",
    "    matcher.add(f'{pat_name}', pat_collection, greedy='LONGEST')\n",
    "    \n",
    "    \n",
    "    doc_match = matcher(doc)\n",
    "    \n",
    "    \n",
    "    list_container = []\n",
    "    for match in doc_match:\n",
    "        start = match[1]\n",
    "        end = match[2]\n",
    "        \n",
    "        result_lemma = doc[start:end]\n",
    "        result_lemma = [(i.lemma_ + i.whitespace_) for i in result_lemma] # new!\n",
    "        result_lemma = ''.join(result_lemma).strip()\n",
    "\n",
    "        result_token = doc[start:end]\n",
    "        result_token = [(i.text + i.whitespace_) for i in result_token] # new!\n",
    "        result_token = ''.join(result_token).strip()\n",
    "\n",
    "        result_pos = doc[start:end]\n",
    "        result_pos = [i.pos_ for i in result_pos] # new!\n",
    "        result_pos = ' '.join(result_pos).strip()\n",
    "        \n",
    "        if len(result_lemma.split()) > 1:\n",
    "            list_container.append((result_token, result_lemma, result_pos))\n",
    "\n",
    "    return list_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.mkdir('IATA_TRANSCRIPTION_PATTERNS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for root, dirs, files in os.walk('NLP/'):\n",
    "#     files = sorted(files)\n",
    "#     files_path = [os.path.join(root, file) for file in files if file.endswith('.pkl')]\n",
    "#     files_path = [f'./{file}' for file in files_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_path = ['EN_STEEL.pkl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Where to save results?\n",
      "Give a name for the directory!\n",
      " NLP_RESULTS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are in NLP_RESULTS folder\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "channels_dir = input('''Where to save results?\n",
    "Give a name for the directory!\n",
    "''')\n",
    "Path(channels_dir).mkdir(parents=True, exist_ok=True)\n",
    "channels_dir = re.sub(r'[\\/\\.]+', '', channels_dir)\n",
    "print(f'Results are in {channels_dir} folder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing EN_STEEL.pkl Batch 1 of 1\n",
      "Starting NLP\n",
      "Current Time = 21:48:28.110243\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017016887664794922,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 33,
       "postfix": null,
       "prefix": "Pandas Apply",
       "rate": null,
       "total": 5191,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04117e0e7ff240c6822f2023ac9813df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/5191 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 21:49:21.372240\n",
      "Finished NLP\n",
      "Total NLP Duration: 0.8833333333333333 minutes\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01400136947631836,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 33,
       "postfix": null,
       "prefix": "Pandas Apply",
       "rate": null,
       "total": 5191,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5429b7b38aaa4ddd924da938dde9b73c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/5191 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.021994590759277344,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 33,
       "postfix": null,
       "prefix": "Pandas Apply",
       "rate": null,
       "total": 12532,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ebf73e7a3e547af9adfca245571eaa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/12532 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01799178123474121,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 33,
       "postfix": null,
       "prefix": "Pandas Apply",
       "rate": null,
       "total": 5191,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4a8ff1c17444389aa50d0ee56579653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/5191 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014995574951171875,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 33,
       "postfix": null,
       "prefix": "Pandas Apply",
       "rate": null,
       "total": 4226,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "530ebfe5fb9d42a383a95e0f1b827992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/4226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013003826141357422,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 33,
       "postfix": null,
       "prefix": "Pandas Apply",
       "rate": null,
       "total": 5191,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcf4efec30344af38004b3e826b92cf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/5191 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015001535415649414,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 33,
       "postfix": null,
       "prefix": "Pandas Apply",
       "rate": null,
       "total": 21746,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b9c56a2c8a1463f9e449db0e5911a41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/21746 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011996269226074219,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 33,
       "postfix": null,
       "prefix": "Pandas Apply",
       "rate": null,
       "total": 5191,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88824a057b68432ea42554240248bb0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/5191 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01600027084350586,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 33,
       "postfix": null,
       "prefix": "Pandas Apply",
       "rate": null,
       "total": 8070,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f6e44d04e9a4304a2f35b6146fc0e0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/8070 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012998819351196289,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 33,
       "postfix": null,
       "prefix": "Pandas Apply",
       "rate": null,
       "total": 5191,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d88ef783e3448fea37426bf43927c4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/5191 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01400899887084961,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 33,
       "postfix": null,
       "prefix": "Pandas Apply",
       "rate": null,
       "total": 12310,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a334ed4d6c1454aa157c65ed52acb47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/12310 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished EN_STEEL.pkl Batch 1 of 1\n"
     ]
    }
   ],
   "source": [
    "for (idx, file) in enumerate(files_path):\n",
    "    print(f'Processing {file} Batch {idx+1} of {len(files_path)}')\n",
    "\n",
    "    df_temp = pd.read_pickle(file)\n",
    "    \n",
    "    \n",
    "    print('Starting NLP')\n",
    "    \n",
    "    start_nlp = time_now()\n",
    "#     print('Renaming TEXT_PUNCT Column!!')\n",
    "#     df_temp['TEXT'] = df_temp['TEXT_PUNCT'] # Remove this line, if necessar!!!\n",
    "    \n",
    "    df_temp['NLP'] = df_temp['TEXT'].swifter.apply(lambda x: nlp(x))\n",
    "    \n",
    "    finish_nlp = time_now()\n",
    "    print('Finished NLP')\n",
    "    duration  = ((finish_nlp - start_nlp).seconds)/60\n",
    "    print(f'Total NLP Duration: {duration} minutes')\n",
    "    \n",
    "    dict_verbs_gen = dict(Counter(list(chain(*df_temp.NLP.apply(lambda x: [i.lemma_ for i in x if i.pos_ == 'VERB'])))).most_common())\n",
    "    dict_nouns_gen = dict(Counter(list(chain(*df_temp.NLP.apply(lambda x: [i.lemma_ for i in x if i.pos_ == 'NOUN'])))).most_common())\n",
    "    dict_adj_gen = dict(Counter(list(chain(*df_temp.NLP.apply(lambda x: [i.lemma_ for i in x if i.pos_ == 'ADJ'])))).most_common())\n",
    "    dict_adv_gen = dict(Counter(list(chain(*df_temp.NLP.apply(lambda x: [i.lemma_ for i in x if i.pos_ == 'ADV'])))).most_common())\n",
    "    \n",
    "    pd.DataFrame(data = dict_adj_gen.items()).rename(columns={0: 'WORD', 1:'FREQ' }).to_pickle(F'./{channels_dir}/BATCH_{str(idx+1).zfill(2)}_ADJECTIVES.pkl', protocol=4)\n",
    "    pd.DataFrame(data = dict_adv_gen.items()).rename(columns={0: 'WORD', 1:'FREQ' }).to_pickle(F'./{channels_dir}/BATCH_{str(idx+1).zfill(2)}_ADVERBS.pkl', protocol=4)\n",
    "    pd.DataFrame(data = dict_nouns_gen.items()).rename(columns={0: 'WORD', 1:'FREQ' }).to_pickle(F'./{channels_dir}/BATCH_{str(idx+1).zfill(2)}_NOUNS.pkl', protocol=4)\n",
    "    pd.DataFrame(data = dict_verbs_gen.items()).rename(columns={0: 'WORD', 1:'FREQ' }).to_pickle(F'./{channels_dir}/BATCH_{str(idx+1).zfill(2)}_VERBS.pkl', protocol=4)\n",
    "    \n",
    "    \n",
    "    for pat in list_pos_patterns:\n",
    "        pattern_name = pat.upper()\n",
    "        df_temp[pattern_name] = df_temp['NLP'].swifter.apply(lambda x: get_pos_lemma_pattern(x, f'{pat}', [eval(pat)]))\n",
    "        \n",
    "        list_pat = list(chain(*df_temp[pattern_name]))\n",
    "        df_pattern  = pd.DataFrame(data=list_pat)\n",
    "        df_pattern = df_pattern.rename(columns={0: 'TEXT', 1: 'LEMMA', 2: 'POS'})\n",
    "        \n",
    "        dict_pattern = dict(df_pattern['LEMMA'].value_counts())\n",
    "        dict_pattern = {k:v for k,v in dict_pattern.items() if v >= threshold_pattern}\n",
    "        \n",
    "        df_pattern = df_pattern[df_pattern['LEMMA'].swifter.apply(lambda x: x in dict_pattern)].reset_index(drop=True)\n",
    "        df_pattern.to_pickle(F'./{channels_dir}/BATCH_{str(idx+1).zfill(2)}_{pattern_name}.pkl', protocol=4)\n",
    "    print(f'Finished {file} Batch {idx+1} of {len(files_path)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>LANG</th>\n",
       "      <th>LANG_DETECT</th>\n",
       "      <th>LANG_SCORE</th>\n",
       "      <th>NLP</th>\n",
       "      <th>PAT_N_N</th>\n",
       "      <th>PAT_N_P_V</th>\n",
       "      <th>PAT_NOUN</th>\n",
       "      <th>PAT_NOUN_VERB_PHRASE</th>\n",
       "      <th>PAT_VERB_NOUN_PHRASE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://aisusteel.org/en/12537/</td>\n",
       "      <td>The modified unaudited financial results of th...</td>\n",
       "      <td>(__label__en, 0.943916380405426)</td>\n",
       "      <td>__label__en</td>\n",
       "      <td>0.943916</td>\n",
       "      <td>(The, modified, unaudited, financial, results,...</td>\n",
       "      <td>[(unaudited financial results of the Egyptian ...</td>\n",
       "      <td>[(Egyptian Iron and Steel showed net losses, E...</td>\n",
       "      <td>[(unaudited financial results, unaudited finan...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(modified unaudited financial results, modify...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://aisusteel.org/en/12537/</td>\n",
       "      <td>Sales slumped to EGP 1.08 billion in the year ...</td>\n",
       "      <td>(__label__en, 0.964730978012085)</td>\n",
       "      <td>__label__en</td>\n",
       "      <td>0.964731</td>\n",
       "      <td>(Sales, slumped, to, EGP, 1.08, billion, in, t...</td>\n",
       "      <td>[(statement to the Egyptian Exchange, statemen...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(Egyptian Exchange, Egyptian Exchange, PROPN ...</td>\n",
       "      <td>[(Sales slumped, sale slump, NOUN VERB), (year...</td>\n",
       "      <td>[(said in a statement, say in a statement, VER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://aisusteel.org/en/12537/</td>\n",
       "      <td>During the first nine months of FY19/20, the c...</td>\n",
       "      <td>(__label__en, 0.9291689991950989)</td>\n",
       "      <td>__label__en</td>\n",
       "      <td>0.929169</td>\n",
       "      <td>(During, the, first, nine, months, of, FY19/20...</td>\n",
       "      <td>[(net losses of EGP, net loss of EGP, ADJ NOUN...</td>\n",
       "      <td>[(year-ago period, year-ago period, NOUN PUNCT...</td>\n",
       "      <td>[(net losses, net loss, ADJ NOUN), (ago period...</td>\n",
       "      <td>[(company reported, company report, NOUN VERB)]</td>\n",
       "      <td>[(reported net losses, report net loss, VERB A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://aisusteel.org/en/6518/</td>\n",
       "      <td>Nucor Steel has awarded SMS group, Inc. the co...</td>\n",
       "      <td>(__label__en, 0.9582651257514954)</td>\n",
       "      <td>__label__en</td>\n",
       "      <td>0.958265</td>\n",
       "      <td>(Nucor, Steel, has, awarded, SMS, group, ,, In...</td>\n",
       "      <td>[(complete melt shop for the new facility, com...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(complete melt shop, complete melt shop, ADJ ...</td>\n",
       "      <td>[(new facility to be built, new facility to be...</td>\n",
       "      <td>[(supply a complete melt shop, supply a comple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://aisusteel.org/en/6518/</td>\n",
       "      <td>The scope includes two 190 metric ton direct c...</td>\n",
       "      <td>(__label__en, 0.8953480124473572)</td>\n",
       "      <td>__label__en</td>\n",
       "      <td>0.895348</td>\n",
       "      <td>(The, scope, includes, two, 190, metric, ton, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(metric ton direct current electric arc furna...</td>\n",
       "      <td>[(scope includes, scope include, NOUN VERB)]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5186</th>\n",
       "      <td>https://aisusteel.org/en/10150/</td>\n",
       "      <td>Arab countries’ production of crude steel</td>\n",
       "      <td>(__label__en, 0.6892220973968506)</td>\n",
       "      <td>__label__en</td>\n",
       "      <td>0.689222</td>\n",
       "      <td>(Arab, countries, ’, production, of, crude, st...</td>\n",
       "      <td>[(Arab countries’ production, arab country’ pr...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(Arab countries, arab country, ADJ NOUN), (cr...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5187</th>\n",
       "      <td>https://aisusteel.org/en/9028/</td>\n",
       "      <td>According to the data provided by the Turkish ...</td>\n",
       "      <td>(__label__en, 0.9031760096549988)</td>\n",
       "      <td>__label__en</td>\n",
       "      <td>0.903176</td>\n",
       "      <td>(According, to, the, data, provided, by, the, ...</td>\n",
       "      <td>[(May this year Turkey, May this year Turkey, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(Turkish Statistical Institute, Turkish Stati...</td>\n",
       "      <td>[(data provided, datum provide, NOUN VERB), (h...</td>\n",
       "      <td>[(provided by the Turkish Statistical Institut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5188</th>\n",
       "      <td>https://aisusteel.org/en/9028/</td>\n",
       "      <td>The revenue from these imports amounted to $41...</td>\n",
       "      <td>(__label__en, 0.9179209470748901)</td>\n",
       "      <td>__label__en</td>\n",
       "      <td>0.917921</td>\n",
       "      <td>(The, revenue, from, these, imports, amounted,...</td>\n",
       "      <td>[(same month of the previous year, same month ...</td>\n",
       "      <td>[(month and increasing, month and increase, NO...</td>\n",
       "      <td>[(% month, % month, NOUN NOUN), (same month, s...</td>\n",
       "      <td>[(imports amounted, import amount, NOUN VERB),...</td>\n",
       "      <td>[(compared to the same month, compare to the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5189</th>\n",
       "      <td>https://aisusteel.org/en/9028/</td>\n",
       "      <td>Meanwhile, in the first five months of this ye...</td>\n",
       "      <td>(__label__en, 0.8969374895095825)</td>\n",
       "      <td>__label__en</td>\n",
       "      <td>0.896937</td>\n",
       "      <td>(Meanwhile, ,, in, the, first, five, months, o...</td>\n",
       "      <td>[(months of this year, month of this year, NOU...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(HRC imports, HRC import, PROPN NOUN), (metri...</td>\n",
       "      <td>[(imports amounted, import amount, NOUN VERB),...</td>\n",
       "      <td>[(compared to the same period, compare to the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5190</th>\n",
       "      <td>https://aisusteel.org/en/9028/</td>\n",
       "      <td>In the given period, Russia ranked first among...</td>\n",
       "      <td>(__label__en, 0.9309320449829102)</td>\n",
       "      <td>__label__en</td>\n",
       "      <td>0.930932</td>\n",
       "      <td>(In, the, given, period, ,, Russia, ranked, fi...</td>\n",
       "      <td>[(Turkey’s HRC import sources, Turkey’s HRC im...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(HRC import sources, HRC import source, PROPN...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(ranked first among Turkey, rank first among ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5191 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  URL  \\\n",
       "0     https://aisusteel.org/en/12537/   \n",
       "1     https://aisusteel.org/en/12537/   \n",
       "2     https://aisusteel.org/en/12537/   \n",
       "3      https://aisusteel.org/en/6518/   \n",
       "4      https://aisusteel.org/en/6518/   \n",
       "...                               ...   \n",
       "5186  https://aisusteel.org/en/10150/   \n",
       "5187   https://aisusteel.org/en/9028/   \n",
       "5188   https://aisusteel.org/en/9028/   \n",
       "5189   https://aisusteel.org/en/9028/   \n",
       "5190   https://aisusteel.org/en/9028/   \n",
       "\n",
       "                                                   TEXT  \\\n",
       "0     The modified unaudited financial results of th...   \n",
       "1     Sales slumped to EGP 1.08 billion in the year ...   \n",
       "2     During the first nine months of FY19/20, the c...   \n",
       "3     Nucor Steel has awarded SMS group, Inc. the co...   \n",
       "4     The scope includes two 190 metric ton direct c...   \n",
       "...                                                 ...   \n",
       "5186          Arab countries’ production of crude steel   \n",
       "5187  According to the data provided by the Turkish ...   \n",
       "5188  The revenue from these imports amounted to $41...   \n",
       "5189  Meanwhile, in the first five months of this ye...   \n",
       "5190  In the given period, Russia ranked first among...   \n",
       "\n",
       "                                   LANG  LANG_DETECT  LANG_SCORE  \\\n",
       "0      (__label__en, 0.943916380405426)  __label__en    0.943916   \n",
       "1      (__label__en, 0.964730978012085)  __label__en    0.964731   \n",
       "2     (__label__en, 0.9291689991950989)  __label__en    0.929169   \n",
       "3     (__label__en, 0.9582651257514954)  __label__en    0.958265   \n",
       "4     (__label__en, 0.8953480124473572)  __label__en    0.895348   \n",
       "...                                 ...          ...         ...   \n",
       "5186  (__label__en, 0.6892220973968506)  __label__en    0.689222   \n",
       "5187  (__label__en, 0.9031760096549988)  __label__en    0.903176   \n",
       "5188  (__label__en, 0.9179209470748901)  __label__en    0.917921   \n",
       "5189  (__label__en, 0.8969374895095825)  __label__en    0.896937   \n",
       "5190  (__label__en, 0.9309320449829102)  __label__en    0.930932   \n",
       "\n",
       "                                                    NLP  \\\n",
       "0     (The, modified, unaudited, financial, results,...   \n",
       "1     (Sales, slumped, to, EGP, 1.08, billion, in, t...   \n",
       "2     (During, the, first, nine, months, of, FY19/20...   \n",
       "3     (Nucor, Steel, has, awarded, SMS, group, ,, In...   \n",
       "4     (The, scope, includes, two, 190, metric, ton, ...   \n",
       "...                                                 ...   \n",
       "5186  (Arab, countries, ’, production, of, crude, st...   \n",
       "5187  (According, to, the, data, provided, by, the, ...   \n",
       "5188  (The, revenue, from, these, imports, amounted,...   \n",
       "5189  (Meanwhile, ,, in, the, first, five, months, o...   \n",
       "5190  (In, the, given, period, ,, Russia, ranked, fi...   \n",
       "\n",
       "                                                PAT_N_N  \\\n",
       "0     [(unaudited financial results of the Egyptian ...   \n",
       "1     [(statement to the Egyptian Exchange, statemen...   \n",
       "2     [(net losses of EGP, net loss of EGP, ADJ NOUN...   \n",
       "3     [(complete melt shop for the new facility, com...   \n",
       "4                                                    []   \n",
       "...                                                 ...   \n",
       "5186  [(Arab countries’ production, arab country’ pr...   \n",
       "5187  [(May this year Turkey, May this year Turkey, ...   \n",
       "5188  [(same month of the previous year, same month ...   \n",
       "5189  [(months of this year, month of this year, NOU...   \n",
       "5190  [(Turkey’s HRC import sources, Turkey’s HRC im...   \n",
       "\n",
       "                                              PAT_N_P_V  \\\n",
       "0     [(Egyptian Iron and Steel showed net losses, E...   \n",
       "1                                                    []   \n",
       "2     [(year-ago period, year-ago period, NOUN PUNCT...   \n",
       "3                                                    []   \n",
       "4                                                    []   \n",
       "...                                                 ...   \n",
       "5186                                                 []   \n",
       "5187                                                 []   \n",
       "5188  [(month and increasing, month and increase, NO...   \n",
       "5189                                                 []   \n",
       "5190                                                 []   \n",
       "\n",
       "                                               PAT_NOUN  \\\n",
       "0     [(unaudited financial results, unaudited finan...   \n",
       "1     [(Egyptian Exchange, Egyptian Exchange, PROPN ...   \n",
       "2     [(net losses, net loss, ADJ NOUN), (ago period...   \n",
       "3     [(complete melt shop, complete melt shop, ADJ ...   \n",
       "4     [(metric ton direct current electric arc furna...   \n",
       "...                                                 ...   \n",
       "5186  [(Arab countries, arab country, ADJ NOUN), (cr...   \n",
       "5187  [(Turkish Statistical Institute, Turkish Stati...   \n",
       "5188  [(% month, % month, NOUN NOUN), (same month, s...   \n",
       "5189  [(HRC imports, HRC import, PROPN NOUN), (metri...   \n",
       "5190  [(HRC import sources, HRC import source, PROPN...   \n",
       "\n",
       "                                   PAT_NOUN_VERB_PHRASE  \\\n",
       "0                                                    []   \n",
       "1     [(Sales slumped, sale slump, NOUN VERB), (year...   \n",
       "2       [(company reported, company report, NOUN VERB)]   \n",
       "3     [(new facility to be built, new facility to be...   \n",
       "4          [(scope includes, scope include, NOUN VERB)]   \n",
       "...                                                 ...   \n",
       "5186                                                 []   \n",
       "5187  [(data provided, datum provide, NOUN VERB), (h...   \n",
       "5188  [(imports amounted, import amount, NOUN VERB),...   \n",
       "5189  [(imports amounted, import amount, NOUN VERB),...   \n",
       "5190                                                 []   \n",
       "\n",
       "                                   PAT_VERB_NOUN_PHRASE  \n",
       "0     [(modified unaudited financial results, modify...  \n",
       "1     [(said in a statement, say in a statement, VER...  \n",
       "2     [(reported net losses, report net loss, VERB A...  \n",
       "3     [(supply a complete melt shop, supply a comple...  \n",
       "4                                                    []  \n",
       "...                                                 ...  \n",
       "5186                                                 []  \n",
       "5187  [(provided by the Turkish Statistical Institut...  \n",
       "5188  [(compared to the same month, compare to the s...  \n",
       "5189  [(compared to the same period, compare to the ...  \n",
       "5190  [(ranked first among Turkey, rank first among ...  \n",
       "\n",
       "[5191 rows x 11 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WORD</th>\n",
       "      <th>FREQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>steel</td>\n",
       "      <td>2060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>year</td>\n",
       "      <td>1905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>%</td>\n",
       "      <td>1741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>price</td>\n",
       "      <td>1054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iron</td>\n",
       "      <td>879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2848</th>\n",
       "      <td>will</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2849</th>\n",
       "      <td>bond</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2850</th>\n",
       "      <td>leap</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2851</th>\n",
       "      <td>enhancement</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2852</th>\n",
       "      <td>valorization</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2853 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              WORD  FREQ\n",
       "0            steel  2060\n",
       "1             year  1905\n",
       "2                %  1741\n",
       "3            price  1054\n",
       "4             iron   879\n",
       "...            ...   ...\n",
       "2848          will     1\n",
       "2849          bond     1\n",
       "2850          leap     1\n",
       "2851   enhancement     1\n",
       "2852  valorization     1\n",
       "\n",
       "[2853 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_pickle('NLP_RESULTS/BATCH_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m97",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m97"
  },
  "kernelspec": {
   "display_name": "string_similarity",
   "language": "python",
   "name": "string_similarity"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
